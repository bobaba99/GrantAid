# Strategic Alignment and Experience Evaluation: A Comprehensive Framework for Canadian Research Funding

## 1. Introduction: The Paradigm Shift in Research Assessment

The landscape of research funding evaluation in Canada and globally is undergoing a profound paradigmatic shift, moving away from quantitative metrics toward qualitative, narrative-driven assessments. Historically, the assessment cultures within major funding bodies relied heavily on bibliometric proxies—such as Journal Impact Factors (JIF), h-indices, and raw publication counts—to define "excellence." This traditional model often marginalized diverse contributions, non-traditional career paths, and the intrinsic value of community-engaged scholarship. However, the adoption of the San Francisco Declaration on Research Assessment (DORA) by the Canadian Institutes of Health Research (CIHR), the Natural Sciences and Engineering Research Council (NSERC), and the Fonds de recherche du Québec – Santé (FRQS) signals a critical transition.

This report delivers a comprehensive, facet-oriented rubric designed to evaluate an applicant's experience—spanning academic, professional, and volunteer domains—against the strategic visions of these key agencies. Unlike traditional grading schemes that focus solely on academic records (transcripts and GPAs), this framework prioritizes the reframing of experiences to demonstrate competency, impact, and strategic fit. It is designed to assist grant facilitators, mentors, and applicants in translating diverse life experiences into the precise lexicon of "research excellence" required by modern funding mandates. By deconstructing the strategic priorities of Canada's tri-agencies and aligning them with the principles of DORA, this document serves as both a rigorous assessment tool and a developmental guide for crafting competitive, narrative-based funding applications.

### 1.1 The DORA Context and the "Narrative CV"

The San Francisco Declaration on Research Assessment (DORA) fundamentally alters how "experience" is evaluated. The declaration explicitly recommends that funding agencies eliminate the use of journal-based metrics as surrogate measures of quality for individual research articles or scientists.[1] Instead, DORA advocates for the assessment of research on its own merits and the consideration of a broad range of impact measures, including qualitative indicators such as influence on policy and practice.[3]

This shift has necessitated the introduction of "Narrative CVs" and "Most Significant Contribution" statements. These formats require applicants to provide structured, written descriptions of their contributions and achievements, reflecting a broader range of skills and experiences than traditional academic CVs.[4] Consequently, the ability to narrate one's experience—to tell the story of why a specific volunteer role or professional project matters to the research enterprise—has become a core competency for grant success. This rubric is specifically calibrated to evaluate that narrative capability.

---

## 2. The Strategic Ecosystem: Deconstructing Agency Visions

To create an effective rubric, one must first deconstruct the definitions of "excellence" and "impact" utilized by the funding agencies. Success in grant applications is no longer merely a function of scientific merit; it is increasingly dependent on the alignment between the applicant's experiential profile and the agency's strategic roadmap.

### 2.1 Canadian Institutes of Health Research (CIHR): A Vision for 2031

CIHR's Strategic Plan 2021–2031 establishes a framework that moves beyond pure biomedical discovery to encompass health equity, Indigenous self-determination, and diverse ways of knowing. The agency has outlined five core priorities that serve as the benchmarks for "Strategic Fit" in our rubric.[6]

#### Priority A: Advance Research Excellence in All Its Diversity

CIHR has explicitly broadened its definition of excellence. It mandates that funded research be "findable, accessible, interoperable, and reproducible" (FAIR principles) and champions a concept of excellence that values Equity, Diversity, and Inclusion (EDI).[8]

**Implication for Experience Assessment:** Experience should not be measured solely by output volume but by the diversity of outputs (e.g., open datasets, community workshops) and the inclusivity of the research environment fostered by the applicant. An applicant who has volunteered to organize open science repositories or EDI workshops demonstrates a higher "Fit" score than one with only traditional publications but no engagement with broader research culture.

#### Priority B: Strengthen Canadian Health Research Capacity

This priority focuses on the "investigator-initiated" research ecosystem and training, emphasizing the need to support trainees in diverse career paths.[6]

**Implication for Experience Assessment:** Applicants must demonstrate a track record of not just supervising students but mentoring them toward diverse outcomes. Experience in "teaching," "mentorship," or "career counseling" (even in volunteer capacities) becomes highly relevant. The rubric must assess the "training environment" as a distinct competency, looking for evidence of skill development in trainees beyond technical lab work.[9]

#### Priority C: Accelerate the Self-Determination of Indigenous Peoples

CIHR is committed to removing barriers to Indigenous-led research and implementing the Building a Healthier Future action plan.[7]

**Implication for Experience Assessment:** Any experience involving Indigenous communities must be evaluated through the lens of cultural safety and OCAP® principles (Ownership, Control, Access, and Possession). "Volunteer" experience in Indigenous communities must be reframed as "community engagement" and "relationship building," which are critical research competencies in this context. The rubric penalizes "extractive" research experiences and rewards reciprocal partnerships.[11]

#### Priority D: Pursue Health Equity through Research

This involves championing research on inequitable health outcomes and determinants of health.[6]

**Implication for Experience Assessment:** Experience in social justice organizations, advocacy groups, food banks, or policy development is highly relevant here. These roles demonstrate a lived understanding of health inequities, which is often more valuable for "Strategic Fit" than purely theoretical coursework.

#### Priority E: Integrate Evidence in Health Decisions

This focuses on knowledge mobilization (KMb) and the science of implementation.[12]

**Implication for Experience Assessment:** Professional experience in healthcare administration, policy analysis, or industry is crucial. The rubric values "decision-making" and "system innovation" experience as evidence of the ability to integrate evidence into practice.

### 2.2 NSERC 2030: Discovery, Innovation, Inclusion

NSERC's strategic vision, NSERC 2030, is anchored in three pillars: Discovery, Innovation, and Inclusion. This document guides the evaluation of experience for natural sciences and engineering applications.[13]

#### The Discovery Pillar

NSERC continues to support fundamental research ("Discovery") but emphasizes that this research must strengthen Canada's position as a global sustainability leader.[13]

**Implication for Experience Assessment:** Evaluation of "Competency" must look for foundational scientific contributions. However, "Discovery" is now coupled with "Sustainability," suggesting that experience in environmental stewardship, sustainable engineering practices, or "Green Labs" initiatives enhances an applicant's profile.

#### The Innovation Pillar

This pillar focuses on translating discovery into impact through partnerships with industry, non-profits, and other sectors.[15]

**Implication for Experience Assessment:** "Professional experience" in industry is a major asset, not a distraction from academia. The rubric assesses the applicant's ability to bridge the gap between academia and application. Skills such as "intellectual property management," "industrial R&D," "technical reporting," and "start-up leadership" are key indicators of fit.[16]

#### The Inclusion Pillar

NSERC explicitly aims to expand the talent pool and support Indigenous research priorities.[13]

**Implication for Experience Assessment:** Similar to CIHR, NSERC requires a demonstration of EDI competence. The rubric must evaluate an applicant's past actions in fostering inclusive teams. This transforms "volunteer work" in STEM outreach (e.g., "Girls in Coding," "Let's Talk Science") from a "nice-to-have" extracurricular into core evidence of "Strategic Fit".[17]

### 2.3 Fonds de recherche du Québec – Santé (FRQS)

The FRQS Strategic Plan (2022–2025) and its Common General Rules emphasize "sustainable health," intersectoral research, and the training of the next generation.[18]

#### Intersectoral and Sustainable Health

FRQS actively encourages the consolidation of interdisciplinary research clusters and the connection between science and society.[18]

**Implication for Experience Assessment:** The "Fit" facet must assess the applicant's ability to work across boundaries (e.g., engineering and health, sociology and medicine). Experience in "multidisciplinary teams" or "cross-sectoral working groups" is a high-value competency. The rubric looks for evidence of "dialogue between science and society".[20]

#### Student Training and Excellence

FRQS places significant weight on the academic record and the progress of the applicant. While the user specified academic records are less relevant for the experience rubric, the trajectory of the applicant is vital.[21]

**Implication for Experience Assessment:** The rubric assesses "momentum"—how experience builds upon education to create an independent researcher profile. It looks for "Relevant experience and scientific achievements" as a specific sub-criterion.[21]

---

## 3. Facet-Oriented Evaluation Rubric

This section details the comprehensive rubric. It is designed to be "facet-oriented," isolating specific qualities (Competency, Fit, Impact, Narrative Flow) to provide targeted rating and feedback. The scoring scale (1-5) aligns with CIHR's descriptors (Outstanding, Excellent, Very Good, Fair, Poor)[23] and NSERC's merit indicators.[24]

### 3.1 Facet A: Applicant's Competency & Capacity (The "Who")

This facet evaluates the applicant's capability to conduct the proposed research based on their track record. Under DORA, "Competency" is redefined to include a broader range of skills beyond technical expertise, such as leadership, resource management, and mentorship.

**Key Evaluation Questions:**
- Does the applicant demonstrate the specific technical skills required for the project?
- Is there evidence of leadership and the ability to manage resources (human and financial)?
- Has the applicant demonstrated resilience and productivity relative to their career stage?

#### Rubric Matrix: Competency & Capacity

| Score | Descriptor | Scientific/Methodological Expertise | Leadership & Mentorship (HQP) | Transferable Skills Integration |
|-------|-----------|-------------------------------------|-------------------------------|--------------------------------|
| **5** | Outstanding (4.5–4.9) | Exemplary mastery. Contributions are groundbreaking. Expertise is clearly distinct and vital to the field. Methodologies are innovative, rigorous, and clearly articulated. Evidence of specialized technical skills is irrefutable. | Transformational leader. Mentorship extends beyond supervision to career sponsorship. Strong evidence of HQP success in diverse sectors. Proactive creation of inclusive environments. History of leading complex teams effectively.[17] | Seamless integration. Professional and volunteer experiences are framed as vital research assets (e.g., project management, governance, budget stewardship). Demonstrates a unique skill set that minimizes project risk.[25] |
| **4** | Excellent (4.0–4.4) | High proficiency. Contributions are significant and recognized. Solid command of methodologies. Applicant is clearly capable of executing the project with minimal oversight. | Strong leader. Consistent supervision record with good outcomes. Mentorship philosophy is articulated but may be standard. Evidence of organizing teams or committees is present.[26] | Strong integration. Transferable skills are highlighted and relevant. Professional experience supports the feasibility of the project (e.g., "industry experience in scaling production"). |
| **3** | Very Good (3.5–3.9) | Proficient. Contributions are solid but may lack novelty. Expertise is adequate for the project but not distinguishing. May require some external support for specific methodologies. | Competent leader. Supervision is adequate but lacks evidence of specific mentorship outcomes. HQP training plan is generic. Leadership roles are listed but impact is unclear. | Partial integration. Skills from other sectors are listed but not effectively connected to research capability. "Volunteer" work is treated as a separate, unrelated list of hobbies. |
| **2** | Fair (3.0–3.4) | Developing. Gaps in expertise relative to the proposed project. Contributions are minor or incremental. Concerns about ability to execute independent research. | Limited leadership. Minimal supervision experience or lack of clarity on the applicant's role in mentoring. No evidence of leading initiatives or teams. | Weak integration. Professional/volunteer experience is mentioned but appears irrelevant or "padding." No clear transfer of skills to the research context. |
| **1** | Poor (0.0–2.9) | Insufficient. Lack of track record to support the proposal. Fundamental gaps in required knowledge. | No evidence. No track record of supervision or leadership. Passive participation in all listed activities. | Disjointed. CV lists activities without context. Skills are not demonstrated or are irrelevant. |

### 3.2 Facet B: Fit with Program's Priorities (The "Why" and "Where")

This facet assesses the alignment between the applicant's experience/proposal and the agency's strategic goals (CIHR Priorities, NSERC Pillars, FRQS Strategy). This is where the "Strategic Ecosystem" analysis is applied.

**Key Evaluation Questions:**
- Does the applicant's profile align with the specific strategic priorities of the target agency?
- Is Equity, Diversity, and Inclusion (EDI) integrated meaningfully into the experience profile?
- Does the applicant demonstrate capacity for Knowledge Mobilization (KMb)?

#### Rubric Matrix: Fit with Program Priorities

| Score | Descriptor | Strategic Alignment (CIHR/NSERC/FRQS) | EDI & Indigenous Research Integration | Knowledge Mobilization (KMb) Capacity |
|-------|-----------|---------------------------------------|--------------------------------------|--------------------------------------|
| **5** | Outstanding | Perfect alignment. The narrative explicitly maps experiences to specific agency priorities (e.g., CIHR Priority B, NSERC Innovation). The fit feels natural and inevitable. The applicant speaks the agency's "language" fluently. | Deeply embedded. EDI is integral to the research design and team composition. Indigenous research (if applicable) strictly adheres to OCAP/TCPS2. Concrete examples of past EDI leadership (e.g., policy change, removing barriers).[27] | Sophisticated strategy. KMb is co-created with users. Experience demonstrates a history of "integrated KT" rather than just "end-of-grant" dissemination. Evidence of engaging policymakers or patients during the process.[28] |
| **4** | Excellent | Strong alignment. Clear connections to agency goals. The applicant understands the funding mandate and addresses it directly. | Thoughtful integration. EDI is addressed with specific plans, avoiding boilerplate language. Evidence of EDI training or awareness. Past experience in diverse teams is highlighted. | Solid strategy. KMb plan involves relevant stakeholders. Past experience shows ability to communicate to non-academic audiences (e.g., op-eds, public workshops).[29] |
| **3** | Very Good | General alignment. Fits the broad subject area but lacks connection to specific strategic pillars (e.g., fits "health" but ignores "equity" or "indigeneity"). | Superficial integration. EDI statement is generic or focuses solely on "recruitment diversity" without addressing inclusion or equity. "Blind recruitment" cited as the only strategy. | Standard strategy. KMb is limited to conference presentations and publications. "Impact" is defined narrowly as academic citation. |
| **2** | Fair | Weak alignment. The project is technically eligible but misses the spirit of the funding opportunity (e.g., submitting a pure biology project to a clinical health stream without clinical partners). | Tokenistic. EDI is treated as a checkbox. "Token" members included without substantive roles. No evidence of understanding systemic barriers. | Passive strategy. No clear plan for dissemination beyond academia. Reliance on "website posting" as KMb. |
| **1** | Poor | Misaligned. Does not fit the agency mandate. | Absent/Harmful. No mention of EDI, or approaches that reinforce bias. | None. No KMb consideration. |

### 3.3 Facet C: Impact and Value (The "So What")

This facet evaluates the significance of the applicant's contributions. Under DORA, this must focus on the content and influence of the work, not the venue.

**Key Evaluation Questions:**
- Who has used the applicant's work? (Researchers, policymakers, public, industry).
- What tangible outcomes have resulted from the applicant's activities?
- How compelling is the "Most Significant Contributions" statement?

#### Rubric Matrix: Impact & Value

| Score | Descriptor | Reach & Influence of Contributions | Quality of "Most Significant Contributions" Statement | Evidence of Impact (DORA-aligned) |
|-------|-----------|-----------------------------------|-----------------------------------------------------|----------------------------------|
| **5** | Outstanding | Global/Systemic. Work has influenced policy, practice, or fundamental thought in the field. Reach extends beyond the academy to industry, government, or civil society. | Compelling narrative. Describes the "journey" of the research. Contextualizes the work (e.g., "despite limited resources..."). Focuses on quality and utility of outputs. Explicitly avoids JIF metrics.[10] | Diverse evidence. Uses qualitative and quantitative indicators (e.g., "adopted by WHO," "open-source code used by 1000 users," "testimony from community partners," "training manual adopted by university").[1] |
| **4** | Excellent | National/Field-Specific. Work is highly cited or used by peers. Some influence on practice or guidelines. Strong presence in the national community. | Clear narrative. Explains the significance of key works. Good use of context to explain the applicant's role. | Strong evidence. Mix of citations and some qualitative indicators (e.g., media coverage, patent applications, invited lectures).[10] |
| **3** | Very Good | Incremental. Contribution to specific sub-field. Limited reach outside immediate peer group. | Descriptive. Lists what was done rather than why it matters. Relies heavily on journal names as proxies for quality. | Metric-focused. Relies on JIF or H-index. Lacks qualitative evidence of utility or broader societal relevance. |
| **2** | Fair | Limited. Contributions are minor or confirmatory. Little evidence of use by others. | List-based. Just a prose version of the CV list. No argument for significance or context provided. | Weak evidence. "Published in [Journal]" is the only evidence provided. |
| **1** | Poor | Negligible. No clear contribution to knowledge. | Absent. Section missing or incoherent. | None. No evidence provided. |

### 3.4 Facet D: Narrative Flow and Coherence (The "How")

This facet evaluates the quality of the application as a persuasive document. A disjointed application that fails to connect experience to future potential will score poorly.

**Key Evaluation Questions:**
- Does the application tell a coherent story about the applicant's professional identity?
- Is the language clear, accessible, and free of jargon?
- Does the narrative build a logical argument for feasibility?

#### Rubric Matrix: Narrative Flow & Coherence

| Score | Descriptor | Storytelling & Identity | Clarity & Accessibility | Persuasion & Feasibility |
|-------|-----------|------------------------|------------------------|-------------------------|
| **5** | Outstanding | Cohesive Identity. The applicant presents a unified persona (e.g., "The entrepreneurial engineer"). Past experiences (volunteer, work, academic) are woven into a single trajectory leading to this project. Gaps are explained proactively and framed as strengths.[30] | Crystal clear. Accessible to non-specialists. Jargon is minimized or explained. "Hook" in the intro grabs attention. Paragraphs transition smoothly. | Irrefutable. The narrative makes the case that only this applicant can do this project. Feasibility is supported by past project management success. |
| **4** | Excellent | Strong Thread. Most experiences are connected. The career path makes sense. The "Why me?" question is answered effectively. | Clear. Generally easy to read. Logical structure. Minor jargon issues but overall accessible. | Convincing. Good case for feasibility. Strengths are highlighted effectively. |
| **3** | Very Good | Segmented. Academic, work, and volunteer lives feel like separate silos. The reader has to work to see the connection between the "volunteer" persona and the "researcher" persona. | Technocratic. Heavy on jargon. Dry academic tone. Hard for a generalist reviewer to follow. | Plausible. Feasibility is assumed rather than demonstrated. Narrative relies on "trust me" rather than evidence. |
| **2** | Fair | Fragmented. Confusing timeline or gaps that raise questions. Contradictory information. The applicant seems unsure of their own professional identity. | Obscure. Poorly organized. Dense text blocks. Frequent grammatical errors that distract from the content. | Unconvincing. Doubts raised about ability to execute. Narrative highlights weaknesses rather than mitigating them. |
| **1** | Poor | Incoherent. No logical flow. Random list of facts. | Unreadable. Major grammatical issues or lack of structure. | Not Feasible. Proposal feels unrealistic based on the narrative provided. |

---

## 4. The Art of Reframing Experience

This section constitutes the core developmental utility of the report. It provides actionable strategies and "before and after" examples to help applicants reframe their experiences to align with the rubric's high-scoring descriptors.

### 4.1 Reframing "Volunteer" Experience

**Context:** Volunteer work is often undervalued by applicants as "service" or "hobbies." However, under the NSERC/CIHR rubrics (specifically Facets A and B), it is a goldmine for evidencing Leadership, EDI, and KMb.

**Theoretical Basis:**
DORA and the Tri-Agency EDI Action Plan value "diverse contributions." Volunteerism often involves "soft skills" that are actually critical "hard skills" for research management: conflict resolution, resource allocation, and public engagement.[31]

#### Case Study 1: The "Service" Volunteer vs. The "Community Leader"

| Original Description (Weak) | Reframed Description (Strong - Competency/Fit Focused) | Target Facet & Reasoning |
|-----------------------------|-------------------------------------------------------|--------------------------|
| "Volunteered at the local food bank (2019-2021). Packed boxes and helped distribute food to families." | "Served as Logistics Coordinator for a community food security initiative. Managed a team of 15 volunteers (Leadership) and optimized inventory tracking, reducing waste by 20% (Innovation). Engaged with diverse community members to identify culturally appropriate food needs (EDI/Indigenous engagement). This experience honed my ability to manage resources under scarcity, a skill directly transferable to lab budget management." | **Competency:** Demonstrates project management, team leadership, and operational efficiency.<br><br>**Fit:** Aligns with CIHR Priority D (Health Equity) and NSERC Innovation (Process Optimization). |

#### Case Study 2: The "Student Rep" vs. The "Policy Changemaker"

| Original Description (Weak) | Reframed Description (Strong - Competency/Fit Focused) | Target Facet & Reasoning |
|-----------------------------|-------------------------------------------------------|--------------------------|
| "Member of the Graduate Student Association. Attended monthly meetings." | "Elected Representative for the Graduate Student Association (Governance). Spearheaded a policy change regarding mental health support for students, involving consultation with 200+ stakeholders (Policy Impact). Organized a seminar series on alternative careers, securing $5k in sponsorship (Grant writing/Budgeting)." | **Competency:** Governance, policy development, financial management.<br><br>**Impact:** Tangible policy outcome demonstrates the ability to affect systemic change. |

#### Case Study 3: The "Outreach Helper" vs. The "EDI Champion"

| Original Description (Weak) | Reframed Description (Strong - Competency/Fit Focused) | Target Facet & Reasoning |
|-----------------------------|-------------------------------------------------------|--------------------------|
| "Helped with 'Girls in Science' day once a year." | "Co-Designed and delivered a STEM curriculum for underrepresented youth (EDI Action). Mentored 5 high school students over two years, 3 of whom subsequently pursued science degrees (HQP Training Impact/Long-term tracking). Evaluated program effectiveness using pre/post surveys (Methodology)." | **Fit:** NSERC Inclusion Pillar.<br><br>**Competency:** HQP training, curriculum design, and impact assessment methods. |

### 4.2 Reframing "Professional" and Clinical Experience

**Context:** Applicants often separate their "day jobs" from their "research careers," viewing them as distractions. Under the "Innovation" and "Integrated Evidence" priorities, professional experience is often the strongest evidence of feasibility.

**Theoretical Basis:**
Clinical and industrial roles often involve "real-world evidence" generation and "implementation science." These are highly prized by CIHR and FRQS.[33]

#### Case Study 4: The "Pharmacist" vs. The "Clinical Investigator"

| Original Description (Weak) | Reframed Description (Strong - Competency/Fit Focused) | Target Facet & Reasoning |
|-----------------------------|-------------------------------------------------------|--------------------------|
| "Worked as a pharmacist at Shoppers Drug Mart. Filled prescriptions." | "Clinical Pharmacist responsible for patient medication reviews and adherence monitoring (Data Collection). Collaborated with interdisciplinary teams (GPs, nurses) to optimize complex patient care plans. Identified systemic barriers to medication access in elderly populations, which informs the hypothesis of my proposed research (Health Systems Research/Feasibility)." | **Competency:** Clinical expertise, interdisciplinary collaboration, real-world data generation.<br><br>**Fit:** CIHR Priority E (Integrate Evidence). |

#### Case Study 5: The "Project Manager" vs. The "Industrial Innovator"

| Original Description (Weak) | Reframed Description (Strong - Competency/Fit Focused) | Target Facet & Reasoning |
|-----------------------------|-------------------------------------------------------|--------------------------|
| "Project Manager at a construction firm. Oversaw building sites." | "Managed large-scale infrastructure projects ($2M budget). Implemented risk management protocols and ensured compliance with environmental regulations (Regulatory Knowledge). Used CAD software to model structural integrity (Technical Skill). This role developed my capacity to manage large grants and multi-stakeholder timelines." | **Competency:** Budget oversight (crucial for grant feasibility), risk management, regulatory compliance.<br><br>**Fit:** NSERC Innovation and "Translation to Impact." |

#### Case Study 6: The "Admin Assistant" vs. The "Research Administrator"

| Original Description (Weak) | Reframed Description (Strong - Competency/Fit Focused) | Target Facet & Reasoning |
|-----------------------------|-------------------------------------------------------|--------------------------|
| "Administrative Assistant. Did filing and answered phones." | "Coordinated complex workflows for a department of 20 staff. Managed grant databases and ensured compliance with institutional policies (Research Administration). Developed a new filing system that improved retrieval time by 30% (Process Optimization). This demonstrates my organizational rigor and attention to detail required for data management." | **Competency:** Organizational efficiency, compliance management, process improvement. |

### 4.3 Reframing "Interruptions" (The DORA/EDI Approach)

**Context:** CIHR and NSERC explicitly allow for the explanation of interruptions (COVID-19, parental leave, bereavement) without penalty. The goal is to reframe these not as "lost time" but as periods of resilience or skill maintenance.[34]

**Strategy:**
Do not apologize. State the facts (duration, impact on output), then pivot to what was maintained or learned. This is a narrative technique that builds the "Resilience" character trait in Facet A.

- **Weak Example:** "I had to take 6 months off for medical reasons so I didn't publish anything."
- **Strong Reframing:** "During a 6-month medical leave, I maintained supervision of 2 graduate students via weekly virtual check-ins (Leadership). I utilized this time to complete online certification in Bioinformatics (Skill Acquisition). Upon return, I rapidly re-established my lab, submitting two manuscripts within 3 months, demonstrating high resilience and the ability to maintain research momentum under adverse conditions."

---

## 5. Implementation Guide for Mentors and Applicants

This rubric is a tool to be used iteratively. To maximize its effectiveness, it should be integrated into a structured review process.

### 5.1 The "Gap Analysis" Phase

1. **Map the Experience:** Have the applicant list every role they have held in the last 5-10 years, including unpaid work, caregiving, and community service.
2. **Apply the Facets:** Use the rubric to score the current description of these roles. Be honest—most initial drafts will score 2s and 3s.
3. **Identify Gaps:**
   - Is the "Fit" score low? → Look for volunteer or professional work that touches on equity, policy, or innovation to boost alignment with agency priorities.
   - Is the "Competency" score low on leadership? → Re-mine the "Volunteer" list for instances of governance, organizing, or mentoring.

### 5.2 The "Translation" Phase (Drafting)

1. **Keyword Injection:** Review the agency strategic plan (e.g.[6] for CIHR, [13] for NSERC). Extract keywords like "Self-Determination," "Sustainability," "Intersectoral," "Mobilization."
2. **Rewrite Bullets:** Rewrite CV bullets and narrative sections to include these keywords honestly. (See Section 4.1 and 4.2).
3. **Evidence-Based Impact:** Replace generic adjectives ("passionate," "hard-working") with evidence ("raised $10k," "managed 5 people," "published open dataset").

### 5.3 The "Mock Review" Phase

1. **External Review:** Give the rubric and the application to a colleague outside the immediate field. This simulates the multidisciplinary nature of many review panels (e.g., CIHR Project Grant committees).
2. **Scoring:** Have them score the application using the rubric tables (Section 3).
3. **Feedback:** Focus feedback on "Narrative Flow" (Facet D). If the reviewer cannot identify the "Fit" (Facet B) within the first two pages, the narrative needs restructuring.

### 5.4 Special Considerations for EDI and Indigenous Research

- **Avoid Tokenism:** When evaluating Facet B (EDI), be critical. A statement that says "We welcome everyone" is a Score 2. A statement that says "We have partnered with the Indigenous Health Institute to co-design the protocol and have allocated budget for community elders" is a Score 5.
- **Lived Experience:** Under DORA and EDI guidelines, lived experience (e.g., a researcher with a disability studying accessibility) is a competency. Ensure this is explicitly valued in Facet A.

---

## Citations

1. The San Francisco Declaration on Research Assessment (DORA) - CIHR, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/51731.html
2. San Francisco Declaration on Research Assessment - Wikipedia, accessed January 21, 2026, https://en.wikipedia.org/wiki/San_Francisco_Declaration_on_Research_Assessment
3. The Journal Impact Factor is frequently used as the primary parameter with which to compare the scientific output of - San Francisco Declaration on Research Assessment (DORA), accessed January 21, 2026, https://sfdora.org/read/
4. Narrative CVs: Guidance for Researchers - University of Alberta, accessed January 21, 2026, https://www.ualberta.ca/en/research/services/develop-and-submit-proposal/narrative-cv-guide-for-research.html
5. Narrative CVs: what they are and why use them - UKRI, accessed January 21, 2026, https://www.ukri.org/what-we-do/supporting-healthy-research-and-innovation-culture/research-and-innovation-culture/supporting-the-community-adoption-of-r4r-like-narrative-cvs/narrative-cvs-what-they-are-and-why-use-them/
6. CIHR Strategic Plan 2021–2031 - Canadian Institutes of Health Research, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/52331.html
7. CIHR Strategic Plan 2021–2031: Action Plan for Year 4 (2024–25), accessed January 21, 2026, https://cihr-irsc.gc.ca/e/53974.html
8. CIHR Strategic Plan 2021–2031 - Canadian Institutes of Health Research, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/documents/strategic-plan-priority-a-en.pdf
9. Applying CIHR's Research Excellence Framework – Best Practices for Clinical Trials, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/53947.html
10. Most Significant Contributions Statement Guide - Research at UCalgary, accessed January 21, 2026, https://research.ucalgary.ca/sites/default/files/teams/1/Guidelines_Most_significant_contributions_statement.pdf
11. Reframing Funding Strategies to Build Reciprocity - Eos.org, accessed January 21, 2026, https://eos.org/opinions/reframing-funding-strategies-to-build-reciprocity
12. CIHR Strategic Plan 2021–2031, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/documents/strategic-plan-priority-e-en.pdf
13. NSERC 2030: Discovery. Innovation. Inclusion. | Natural Sciences and Engineering Research Council of Canada, accessed January 21, 2026, https://nserc-crsng.canada.ca/en/about/planning-and-performance-reporting/nserc-2030-discovery-innovation-inclusion
14. accessed January 21, 2026, https://nserc-crsng.canada.ca/en/about/planning-and-performance-reporting/nserc-2030-discovery-innovation-inclusion#:~:text=NSERC's%20next%20long%2Dterm%20strategic,and%20a%20dynamic%20research%20culture.
15. NSERC 2030: Discovery. Innovation. Inclusion., accessed January 21, 2026, https://nserc-crsng.canada.ca/sites/default/files/migrated/_doc/nserc2030/strategicplan_planstrategique_en_1.pdf
16. BEST PRACTICES NSERC FORM 100, accessed January 21, 2026, https://www.queensu.ca/vpr/sites/vprwww/files/uploaded_files/Funding%20Sources/create/NSERC_Form_100_Best_Practices.pdf
17. Guidelines on the assessment of contributions to research, training and mentoring, accessed January 21, 2026, https://nserc-crsng.canada.ca/en/guidelines-assessment-contributions-research-training-and-mentoring
18. Strategic Cluster (RG), 2024-2025 - Fonds de recherche du Québec, accessed January 21, 2026, https://frq.gouv.qc.ca/en/program/strategic-cluster-rg-2024-2025/
19. Message from the Chief Scientist: Important projects in the works for 2023, accessed January 21, 2026, https://frq.gouv.qc.ca/en/message-du-scientifique-en-chef-des-chantiers-ponctueront-lannee-2023/
20. Citizen Consultation on FRQ Strategic Plans 2022-2025: Final Report - Policy Commons, accessed January 21, 2026, https://policycommons.net/artifacts/2237479/lire-le-rapport/2995514/
21. Information guide Training award programs: New evaluation criteria - Fonds de recherche du Québec, accessed January 21, 2026, https://frq.gouv.qc.ca/app/uploads/2021/07/information-guide_training-award-programs-new-evaluation-criteria.pdf
22. Fonds de recherche du Québec - McGill University, accessed January 21, 2026, https://www.mcgill.ca/gps/files/gps/gps_student_frq_fall_2025.pdf
23. CIHR Reviewers' Guide for Doctoral Research Awards, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/33043.html
24. DG Merit Indicators Grid - crsng - nserc, accessed January 21, 2026, https://nserc-crsng.canada.ca/sites/default/files/migrated/_doc/professors-professeurs/dg_merit_indicators_eng_2.pdf
25. PhD transferable skills | University Career Center, accessed January 21, 2026, https://careercenter.umich.edu/article/phd-transferable-skills
26. 3 Ways to Illustrate Leadership Skills in Your Fellowship Application | ProFellow, accessed January 21, 2026, https://www.profellow.com/tips/3-ways-to-illustrate-leadership-skills-in-your-fellowship-application/
27. Equity, Diversity, and Inclusion in Research Grant Applications – Toolkit - Brock University, accessed January 21, 2026, https://brocku.ca/research/wp-content/uploads/sites/271/EDI-in-Grant-Applications-Toolkit-Version-3.pdf
28. Evaluation of CIHR's Knowledge Translation Funding Program, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/47332.html
29. Knowledge Mobilization (KMb) Activities Menu - Research at UCalgary, accessed January 21, 2026, https://research.ucalgary.ca/engage-research/knowledge-mobilization-activities
30. Examples of Personal Statements - Marcus Canada, accessed January 21, 2026, https://marcuseducate.com/wp-content/uploads/2017/11/%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D1%8B-%D1%8D%D1%81%D1%81%D0%B5-%D0%B4%D0%BB%D1%8F-UofT.pdf
31. How to modernise and improve volunteer experiences - Good Grants, accessed January 21, 2026, https://goodgrants.com/resources/articles/how-to-modernise-and-improve-volunteer-experiences/
32. How to Effectively Showcase Volunteer Experience on Your Resume - VolunteerHub, accessed January 21, 2026, https://volunteerhub.com/blog/how-to-effectively-showcase-volunteer-experience-on-your-resume
33. Palliative and End-of-Life Care Initiative: Impact Assessment Report, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/documents/icr_palliative_care_summary_e.pdf
34. Policy and Guidelines on Contributions to Research and Training, accessed January 21, 2026, https://nserc-crsng.canada.ca/en/policy-and-guidelines-contributions-research-and-training
35. How to Turn Volunteer Experience into Resume Highlights, accessed January 21, 2026, https://www.resumly.ai/blog/how-to-turn-volunteer-experience-into-strong-professional-resume-highlights
36. Voluntary Sector Knowledge Mobilization Support Grant 2025-2026 - CIHR, accessed January 21, 2026, https://cihr-irsc.gc.ca/e/36397.html
